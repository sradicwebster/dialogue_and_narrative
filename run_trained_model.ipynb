{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dill\n",
    "from nltk.tokenize import TreebankWordTokenizer as twt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 09:29:20,062 loading file resources/taggers/key_phrase/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "model = SequenceTagger.load('resources/taggers/key_phrase/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 09:09:42,457 loading file resources/taggers/kp_type/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "model = SequenceTagger.load('resources/taggers/kp_type/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as file:\n",
    "    test_text = file.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = 'In the case of an industrial styrene polymerization this would permit to avoid any specific washing or degassing steps , which are necessary in the radical process to remove residual monomer and low molar mass oligomers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"In the case of an industrial styrene polymerization this would permit to avoid any specific washing or degassing steps , which are necessary in the radical process to remove residual monomer and low molar mass oligomers.\" - 36 Tokens]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the case of an industrial <B> styrene <I> polymerization <I> this would permit to avoid any specific washing <B> or degassing <B> steps <I> , which are necessary in the radical process to remove residual <B> monomer <I> and low molar mass oligomers.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = sentence.to_tagged_string().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['industrial', '<B>'],\n",
       " ['styrene', '<I>'],\n",
       " ['polymerization', '<I>'],\n",
       " ['washing', '<B>'],\n",
       " ['degassing', '<B>'],\n",
       " ['steps', '<I>'],\n",
       " ['residual', '<B>'],\n",
       " ['monomer', '<I>']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_words = []\n",
    "for i, word in enumerate(tagged):\n",
    "    if word == '<B>':\n",
    "        kp_words.append(tagged[i-1:i+1])\n",
    "    elif word == '<I>':\n",
    "        kp_words.append(tagged[i-1:i+1])\n",
    "kp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_b = []\n",
    "for i, word in enumerate(kp_words):\n",
    "    if kp_words[i][1] == '<B>':\n",
    "        index_b.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrase = []\n",
    "for i, num in enumerate(index_b):\n",
    "    if i < len(index_b)-1:\n",
    "        key_phrase.append(' '.join([kp_words[j][0] for j in range(num,index_b[i+1])]))\n",
    "    else:\n",
    "        key_phrase.append(' '.join([kp_words[j][0] for j in range(num,len(kp_words))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('test_ks.txt', key_phrase, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perturbative expansion',\n",
       " 'tree-level unitarity bounds',\n",
       " 'loop-improved unitarity']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hmm_tagger.dill', 'rb') as f:\n",
    "    tagger = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'Since perturbative expansion is used, it is impossible to find the exact bounds; instead, one can derive tree-level unitarity bounds or loop-improved unitarity bounds. In this study, we will use unitarity bounds coming from a tree-level analysis'\n",
    "tokens = list(twt().tokenize(example))\n",
    "tagged_words = tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_words = []\n",
    "for i, word in enumerate(tagged_words):\n",
    "    if word[1] == 'B':\n",
    "        kp_words.append(tagged_words[i])\n",
    "    elif word[1] == 'I':\n",
    "        kp_words.append(tagged_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_b = []\n",
    "for i, word in enumerate(kp_words):\n",
    "    if word[1] == 'B':\n",
    "        index_b.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrase = []\n",
    "for i, num in enumerate(index_b):\n",
    "    if i < len(index_b)-1:\n",
    "        key_phrase.append(' '.join([kp_words[j][0] for j in range(num,index_b[i+1])]))\n",
    "    else:\n",
    "        key_phrase.append(' '.join([kp_words[j][0] for j in range(num,len(kp_words))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perturbative expansion',\n",
       " 'exact bounds',\n",
       " 'tree-level unitarity bounds or loop-improved unitarity bounds.',\n",
       " 'unitarity bounds',\n",
       " 'tree-level analysis']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
